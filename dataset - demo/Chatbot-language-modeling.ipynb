{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "import keras.utils as ku \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "file_name = \"all_data.csv\"\n",
    "\n",
    "df = pd.read_csv(file_name)\n",
    "questions = df['question']\n",
    "answers = df['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer()\n",
    "\n",
    "def dataset_preparation(data):\n",
    "\n",
    "    # basic cleanup\n",
    "    corpus = data\n",
    "\n",
    "    # tokenization\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "    # create input sequences using list of tokens\n",
    "    input_sequences = []\n",
    "    for line in corpus:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "\n",
    "    # pad sequences \n",
    "    max_sequence_len = max([len(x) for x in input_sequences])\n",
    "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "    # create predictors and label\n",
    "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "    label = ku.to_categorical(label, num_classes=total_words)\n",
    "\n",
    "    return predictors, label, max_sequence_len, total_words\n",
    "\n",
    "def create_model(predictors, label, max_sequence_len, total_words):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(total_words, 10, input_length=max_sequence_len-1))\n",
    "    model.add(LSTM(150, return_sequences = True))\n",
    "    # model.add(Dropout(0.2))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "    model.fit(predictors, label, epochs=100, verbose=1, callbacks=[earlystop])\n",
    "    print( model.summary() )\n",
    "    return model \n",
    "\n",
    "def generate_text(seed_text, next_words, max_sequence_len):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted = model.predict_classes(token_list, verbose=0)\n",
    "\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7226/7226 [==============================] - 15s 2ms/step - loss: 5.4072 - accuracy: 0.0400\n",
      "Epoch 2/100\n",
      "  96/7226 [..............................] - ETA: 12s - loss: 5.1983 - accuracy: 0.0104"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7226/7226 [==============================] - 13s 2ms/step - loss: 5.2036 - accuracy: 0.0450\n",
      "Epoch 3/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 4.9164 - accuracy: 0.0659\n",
      "Epoch 4/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 4.5679 - accuracy: 0.1053\n",
      "Epoch 5/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 4.2695 - accuracy: 0.1560\n",
      "Epoch 6/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 4.0270 - accuracy: 0.1972\n",
      "Epoch 7/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 3.8434 - accuracy: 0.2303\n",
      "Epoch 8/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 3.6764 - accuracy: 0.2634\n",
      "Epoch 9/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 3.5422 - accuracy: 0.2746\n",
      "Epoch 10/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 3.4157 - accuracy: 0.2986\n",
      "Epoch 11/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 3.3097 - accuracy: 0.3157\n",
      "Epoch 12/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 3.2068 - accuracy: 0.3352\n",
      "Epoch 13/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 3.1142 - accuracy: 0.3498\n",
      "Epoch 14/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 3.0286 - accuracy: 0.3709\n",
      "Epoch 15/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 2.9495 - accuracy: 0.3789\n",
      "Epoch 16/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 2.8811 - accuracy: 0.3882\n",
      "Epoch 17/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 2.8056 - accuracy: 0.4041\n",
      "Epoch 18/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 2.7442 - accuracy: 0.4118\n",
      "Epoch 19/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 2.6787 - accuracy: 0.4164\n",
      "Epoch 20/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 2.6212 - accuracy: 0.4255\n",
      "Epoch 21/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 2.5650 - accuracy: 0.4337\n",
      "Epoch 22/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 2.5077 - accuracy: 0.4445\n",
      "Epoch 23/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 2.4552 - accuracy: 0.4480\n",
      "Epoch 24/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 2.4058 - accuracy: 0.4588\n",
      "Epoch 25/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 2.3485 - accuracy: 0.4700\n",
      "Epoch 26/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 2.3058 - accuracy: 0.4801\n",
      "Epoch 27/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 2.2593 - accuracy: 0.4833\n",
      "Epoch 28/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 2.2150 - accuracy: 0.4929\n",
      "Epoch 29/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 2.1711 - accuracy: 0.5033\n",
      "Epoch 30/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 2.1331 - accuracy: 0.5068\n",
      "Epoch 31/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 2.0930 - accuracy: 0.5152\n",
      "Epoch 32/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 2.0525 - accuracy: 0.5220\n",
      "Epoch 33/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 2.0123 - accuracy: 0.5286\n",
      "Epoch 34/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 1.9766 - accuracy: 0.5392\n",
      "Epoch 35/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 1.9417 - accuracy: 0.5447\n",
      "Epoch 36/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 1.9103 - accuracy: 0.5482\n",
      "Epoch 37/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 1.8737 - accuracy: 0.5544\n",
      "Epoch 38/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 1.8492 - accuracy: 0.5583\n",
      "Epoch 39/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 1.8131 - accuracy: 0.5678\n",
      "Epoch 40/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 1.7844 - accuracy: 0.5756\n",
      "Epoch 41/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 1.7546 - accuracy: 0.5799\n",
      "Epoch 42/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 1.7316 - accuracy: 0.5826\n",
      "Epoch 43/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 1.6996 - accuracy: 0.5875\n",
      "Epoch 44/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 1.6718 - accuracy: 0.5952\n",
      "Epoch 45/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 1.6508 - accuracy: 0.5977\n",
      "Epoch 46/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 1.6183 - accuracy: 0.6059\n",
      "Epoch 47/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 1.5946 - accuracy: 0.6097\n",
      "Epoch 48/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 1.5694 - accuracy: 0.6151\n",
      "Epoch 49/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 1.5492 - accuracy: 0.6180\n",
      "Epoch 50/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 1.5265 - accuracy: 0.6204\n",
      "Epoch 51/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 1.5012 - accuracy: 0.6293\n",
      "Epoch 52/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 1.4817 - accuracy: 0.6333\n",
      "Epoch 53/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 1.4568 - accuracy: 0.6340\n",
      "Epoch 54/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 1.4349 - accuracy: 0.6448\n",
      "Epoch 55/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 1.4190 - accuracy: 0.6456\n",
      "Epoch 56/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 1.3935 - accuracy: 0.6493\n",
      "Epoch 57/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 1.3763 - accuracy: 0.6508\n",
      "Epoch 58/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 1.3574 - accuracy: 0.6612\n",
      "Epoch 59/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 1.3343 - accuracy: 0.6641\n",
      "Epoch 60/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 1.3198 - accuracy: 0.6637\n",
      "Epoch 61/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 1.3092 - accuracy: 0.6676\n",
      "Epoch 62/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 1.2912 - accuracy: 0.6686\n",
      "Epoch 63/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 1.2702 - accuracy: 0.6777\n",
      "Epoch 64/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 1.2515 - accuracy: 0.6827\n",
      "Epoch 65/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 1.2295 - accuracy: 0.6871\n",
      "Epoch 66/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 1.2211 - accuracy: 0.6913\n",
      "Epoch 67/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 1.2000 - accuracy: 0.6960\n",
      "Epoch 68/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 1.1850 - accuracy: 0.6949\n",
      "Epoch 69/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 1.1703 - accuracy: 0.7019\n",
      "Epoch 70/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 1.1549 - accuracy: 0.7062\n",
      "Epoch 71/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 1.1427 - accuracy: 0.7087\n",
      "Epoch 72/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 1.1253 - accuracy: 0.7123\n",
      "Epoch 73/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 1.1085 - accuracy: 0.7108\n",
      "Epoch 74/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 1.0950 - accuracy: 0.7171\n",
      "Epoch 75/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 1.0796 - accuracy: 0.7167\n",
      "Epoch 76/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 1.0700 - accuracy: 0.7207\n",
      "Epoch 77/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 1.0546 - accuracy: 0.7264\n",
      "Epoch 78/100\n",
      "7226/7226 [==============================] - 12s 2ms/step - loss: 1.0416 - accuracy: 0.7270\n",
      "Epoch 79/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 1.0266 - accuracy: 0.7304\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7226/7226 [==============================] - 13s 2ms/step - loss: 1.0206 - accuracy: 0.7311\n",
      "Epoch 81/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 1.0039 - accuracy: 0.7350\n",
      "Epoch 82/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 0.9887 - accuracy: 0.7412\n",
      "Epoch 83/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 0.9779 - accuracy: 0.7461\n",
      "Epoch 84/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 0.9658 - accuracy: 0.7430\n",
      "Epoch 85/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 0.9557 - accuracy: 0.7473\n",
      "Epoch 86/100\n",
      "7226/7226 [==============================] - 14s 2ms/step - loss: 0.9421 - accuracy: 0.7512\n",
      "Epoch 87/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 0.9272 - accuracy: 0.7553\n",
      "Epoch 88/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 0.9178 - accuracy: 0.7566\n",
      "Epoch 89/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 0.9075 - accuracy: 0.7614\n",
      "Epoch 90/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 0.8997 - accuracy: 0.7611\n",
      "Epoch 91/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 0.8857 - accuracy: 0.7661\n",
      "Epoch 92/100\n",
      "7226/7226 [==============================] - 14s 2ms/step - loss: 0.8737 - accuracy: 0.7676\n",
      "Epoch 93/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 0.8642 - accuracy: 0.7681\n",
      "Epoch 94/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 0.8612 - accuracy: 0.7708\n",
      "Epoch 95/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 0.8437 - accuracy: 0.7736\n",
      "Epoch 96/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 0.8344 - accuracy: 0.7761\n",
      "Epoch 97/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 0.8273 - accuracy: 0.7721\n",
      "Epoch 98/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 0.8149 - accuracy: 0.7827\n",
      "Epoch 99/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 0.8047 - accuracy: 0.7847\n",
      "Epoch 100/100\n",
      "7226/7226 [==============================] - 13s 2ms/step - loss: 0.7950 - accuracy: 0.7847\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 52, 10)            5730      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 52, 150)           96600     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               100400    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 573)               57873     \n",
      "=================================================================\n",
      "Total params: 260,603\n",
      "Trainable params: 260,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "predictors, label, max_sequence_len, total_words = dataset_preparation(questions)\n",
    "model = create_model(predictors, label, max_sequence_len, total_words)\n",
    "# model.save_weights('model_weights.h5')\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "điểm chuẩn xét tuyển dựa vào kết quả học tập trung học phổ thông quốc gia gồm những ai không ạ có bị xếp học riêng không ạ có bị thế nào có nhận hơn học phí không ạ có bị xếp học chung trường là bao nhiêu ạ trong tdtu tdtu có giảm không ạ có được thay lập thay ạ có bị xếp lớp học riêng không ạ học phí là bao nhiêu ạ trong quá trình đó là bao nhiêu ạ khu vực 2 có bao nhiêu ngành trong chương trình tiêu chuẩn có trường chương trình chất lượng cao có ngành nào không học tại trường là\n"
     ]
    }
   ],
   "source": [
    "output_sequences = []\n",
    "for line in answers:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        output_sequences.append(n_gram_sequence)\n",
    "# pad sequences \n",
    "max_output_sequences_len = max([len(x) for x in output_sequences])\n",
    "# print(max_output_sequences_len)\n",
    "\n",
    "# model = model.load_weights('model_weights.h5')\n",
    "model = keras.models.load_model('model.h5')\n",
    "print (generate_text(\"điểm chuẩn\", max_output_sequences_len, max_sequence_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
